accelerate==1.3.*
bitsandbytes==0.45.*
colorama
datasets
einops
fastapi==0.112.4
gradio==4.37.*
jinja2==3.1.5
markdown
numba==0.59.*
numpy==1.26.*
pandas
peft==0.12.*
Pillow>=9.5.0
psutil
pydantic==2.8.2
pyyaml
requests
rich
safetensors==0.5.*
scipy
sentencepiece
tensorboard
transformers==4.48.*
tqdm
wandb

# API
SpeechRecognition==3.10.0
flask_cloudflared==0.0.14
sse-starlette==1.6.5
tiktoken

# llama-cpp-python (CUDA, ohne GGML_CUDA_FORCE_MMQ) für Windows + Python 3.10
https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda_tensorcores-0.3.7+cu121-cp310-cp310-win_amd64.whl; platform_system == "Windows" and python_version == "3.10"

# exllamav2 (CUDA) für Windows + Python 3.10
https://github.com/oobabooga/exllamav2/releases/download/v0.2.7/exllamav2-0.2.7+cu121.torch2.4.1-cp310-cp310-win_amd64.whl; platform_system == "Windows" and python_version == "3.10"

# flash_attn (CUDA) für Windows + Python 3.10
https://github.com/oobabooga/flash-attention/releases/download/v2.7.3/flash_attn-2.7.3+cu122torch2.4.1cxx11abiFALSE-cp310-cp310-win_amd64.whl; platform_system == "Windows" and python_version == "3.10"
